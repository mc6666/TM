{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Categorization with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference: [How we Changed Unsupervised LDA to Semi-Supervised GuidedLDA](https://www.freecodecamp.org/news/how-we-changed-unsupervised-lda-to-semi-supervised-guidedlda-e36a95f3a164/)\n",
    "### code：[GuidedLDA: Guided Topic modeling with latent Dirichlet allocation](https://github.com/vi3k6i5/GuidedLDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Description</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Version</th>\n",
       "      <th>Date/Time Opened</th>\n",
       "      <th>Solution Provided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00677507</td>\n",
       "      <td>[WFBS-SVC] Installation on Mac Is Not Full Fea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worry-Free Business Security Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/2018 12:18 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00677513</td>\n",
       "      <td>[WFBS - A] Smart Scan is not updating</td>\n",
       "      <td>CRC proc crash instability unable to keep syst...</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1/1/2018 2:30 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00677518</td>\n",
       "      <td>[WFBS - SVC] Installation issue</td>\n",
       "      <td>Migrated a client to a new computer, the softw...</td>\n",
       "      <td>Worry-Free Business Security Services</td>\n",
       "      <td>6.2 (Beta)</td>\n",
       "      <td>1/1/2018 6:41 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00677669</td>\n",
       "      <td>[MALWARE][WFBS SVC] Wallet Ransomware</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Worry-Free Business Security Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/2018 11:54 PM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00677682</td>\n",
       "      <td>[MALWARE][WFBS S 9.5]Possible Ransomware detec...</td>\n",
       "      <td>OMAN wfbs SYED AIJAZ LOAY INTERNATIONAL LLC ai...</td>\n",
       "      <td>Worry-Free Business Security Standard</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1/2/2018 12:30 AM</td>\n",
       "      <td>Next Action Plan: - check detection on the con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00677799</td>\n",
       "      <td>[WFBS-S] Adding Exclusion to Behavior Monitoring</td>\n",
       "      <td>[Case Description] - client SWA financial plan...</td>\n",
       "      <td>Worry-Free Business Security Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/2/2018 10:37 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00677803</td>\n",
       "      <td>[WFBS-S] Migrating from An Old Server to A New...</td>\n",
       "      <td>Issue: - customer wants to migrate WFBS to new...</td>\n",
       "      <td>Worry-Free Business Security Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/2/2018 10:49 AM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00677816</td>\n",
       "      <td>[WFBS-SVC] Agent cloning</td>\n",
       "      <td>Can Worry Free agent with OS be image cloned/g...</td>\n",
       "      <td>Worry-Free Business Security Services</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1/2/2018 12:02 PM</td>\n",
       "      <td>- manually reset the GUID info on the registry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00677831</td>\n",
       "      <td>[WFBS-SVC] Main Software not Functioning with ...</td>\n",
       "      <td>The latest Trend Micro update prevents one of ...</td>\n",
       "      <td>Worry-Free Business Security Services</td>\n",
       "      <td>6.2 (Beta)</td>\n",
       "      <td>1/2/2018 1:13 PM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00677857</td>\n",
       "      <td>[WFBS-SVC] False Positive: Application Detecte...</td>\n",
       "      <td>[Issue]: False Positive: Application Detected ...</td>\n",
       "      <td>Worry-Free Business Security Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/2/2018 2:38 PM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number                                            Subject  \\\n",
       "0    00677507  [WFBS-SVC] Installation on Mac Is Not Full Fea...   \n",
       "1    00677513              [WFBS - A] Smart Scan is not updating   \n",
       "2    00677518                    [WFBS - SVC] Installation issue   \n",
       "3    00677669              [MALWARE][WFBS SVC] Wallet Ransomware   \n",
       "4    00677682  [MALWARE][WFBS S 9.5]Possible Ransomware detec...   \n",
       "5    00677799   [WFBS-S] Adding Exclusion to Behavior Monitoring   \n",
       "6    00677803  [WFBS-S] Migrating from An Old Server to A New...   \n",
       "7    00677816                           [WFBS-SVC] Agent cloning   \n",
       "8    00677831  [WFBS-SVC] Main Software not Functioning with ...   \n",
       "9    00677857  [WFBS-SVC] False Positive: Application Detecte...   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                                NaN   \n",
       "1  CRC proc crash instability unable to keep syst...   \n",
       "2  Migrated a client to a new computer, the softw...   \n",
       "3                                                NaN   \n",
       "4  OMAN wfbs SYED AIJAZ LOAY INTERNATIONAL LLC ai...   \n",
       "5  [Case Description] - client SWA financial plan...   \n",
       "6  Issue: - customer wants to migrate WFBS to new...   \n",
       "7  Can Worry Free agent with OS be image cloned/g...   \n",
       "8  The latest Trend Micro update prevents one of ...   \n",
       "9  [Issue]: False Positive: Application Detected ...   \n",
       "\n",
       "                            Product Name Product Version   Date/Time Opened  \\\n",
       "0  Worry-Free Business Security Services             NaN  1/1/2018 12:18 AM   \n",
       "1  Worry-Free Business Security Advanced             9.5   1/1/2018 2:30 AM   \n",
       "2  Worry-Free Business Security Services      6.2 (Beta)   1/1/2018 6:41 AM   \n",
       "3  Worry-Free Business Security Services             NaN  1/1/2018 11:54 PM   \n",
       "4  Worry-Free Business Security Standard             9.5  1/2/2018 12:30 AM   \n",
       "5  Worry-Free Business Security Standard             NaN  1/2/2018 10:37 AM   \n",
       "6  Worry-Free Business Security Standard             NaN  1/2/2018 10:49 AM   \n",
       "7  Worry-Free Business Security Services             6.2  1/2/2018 12:02 PM   \n",
       "8  Worry-Free Business Security Services      6.2 (Beta)   1/2/2018 1:13 PM   \n",
       "9  Worry-Free Business Security Standard             NaN   1/2/2018 2:38 PM   \n",
       "\n",
       "                                   Solution Provided  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  Next Action Plan: - check detection on the con...  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7     - manually reset the GUID info on the registry  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./WF Cases 20190517.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import krovetz\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "break_words=list('\\n\\t')\n",
    "prefix_char_remove=list('.*,-')\n",
    "\n",
    "stemmer = krovetz.PyKrovetzStemmer()\n",
    "#stemmer = SnowballStemmer(\"english\")\n",
    "#stemmer.stem('working')\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "word_freqs = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以 regular expression 去除 email、數字、URL、Phone No、序號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_pattern_list=[]\n",
    "re_pattern_list.append('[a-zA-Z0-9_]+\\.(com|org|net)[a-zA-Z0-9_\\.]*$') #email\n",
    "re_pattern_list.append('[0-9_]+') # all digits\n",
    "re_pattern_list.append(\"\\/\\/[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&'\\(\\)\\*\\+,;=.]+$\") # url\n",
    "re_pattern_list.append('[0-9\\-]+') # phone no\n",
    "re_pattern_list.append('[\\u0800-\\u4e00]+') # 日文\n",
    "re_pattern_list.append('(trend|trend\\smicro)') # trend micro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字詞清理函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean words\n",
    "def clean_word(word_0):\n",
    "    word_list=[]\n",
    "    for word in word_0.split('/'):\n",
    "\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "\n",
    "        # remove 網路芳鄰路徑\n",
    "        remote_path=word.split('\\\\')\n",
    "        if len(remote_path) > 0 and len(remote_path[-1])>0:\n",
    "            word=remote_path[-1]\n",
    "        elif len(remote_path) > 1 and len(remote_path[-2])>0:\n",
    "            word=remote_path[-2]\n",
    "        elif len(remote_path) > 2 and len(remote_path[-3])>0:\n",
    "            word=remote_path[-3]\n",
    "\n",
    "        if word[0] == '\"' and word[-1] == '\"':\n",
    "            word=word[1:-1]\n",
    "        if word[0] == \"'\" and word[-1] == \"'\":\n",
    "            word=word[1:-1]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "\n",
    "        # repeat 3 times to remove continous chars\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "\n",
    "        # lemmatize\n",
    "        word=word.strip().lower()\n",
    "        word=stemmer.stem(word)\n",
    "        if word=='':\n",
    "            continue      \n",
    "            \n",
    "        # remove .exe and .com\n",
    "        if word.endswith('.exe') or word.endswith('.com'):\n",
    "            word=word[:-4]\n",
    "            \n",
    "        # 以 regular expression 去除 email、數字、URL、Phone No、序號\n",
    "        is_re_list = False\n",
    "        for pattern1 in re_pattern_list:\n",
    "            result=re.findall(pattern1, word)\n",
    "            if  len(result) > 0:\n",
    "                is_re_list = True\n",
    "                break\n",
    "        if is_re_list:\n",
    "            break\n",
    "            \n",
    "            \n",
    "        # remove the words with one or two characters only\n",
    "        if len(word) <= 2 :\n",
    "            continue\n",
    "        if not (word in stop_words):\n",
    "            word_list.append(word)\n",
    "               \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test get service_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[WFBS-SVC] Installation on Mac Is Not Full Featured'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Subject[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[WFBS-SVCaaa]', '[WFBS-SVC]']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern1 = '\\[[a-zA-Z0-9_\\-]+\\]' # category\n",
    "re.findall(pattern1, '[WFBS-SVCaaa]'+df.Subject[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4660\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern1 = '\\[[a-zA-Z0-9_\\-\\s]+\\]' # service_list pattern, e.g. [WFBS-SVC]\n",
    "\n",
    "# 清理後的 email DESCRIPTION\n",
    "clean_corpus=[]\n",
    "original_corpus=[]\n",
    "for index, line in df.iterrows():\n",
    "    clean_line=\"\"\n",
    "    line = line['Subject']\n",
    "    \n",
    "    # remove service_list, e.g. [WFBS-SVC]\n",
    "    if type(line) == str and len(line) > 0: \n",
    "        service_list = re.findall(pattern1, line)\n",
    "        for service_item in service_list:\n",
    "            line = line.replace(service_item, ' ')          \n",
    "                                  \n",
    "    #print(line)\n",
    "    for break_word in break_words:\n",
    "        #print('-',len(break_word), break_word, '-')\n",
    "        if not type(line) == str or len(line) <= 0: \n",
    "            break\n",
    "        line = line.replace(break_word, ' ')\n",
    "    if not type(line) == str or len(line) <= 0: \n",
    "        #print(type(line))\n",
    "        continue\n",
    "    words = word_tokenize(line) #line.lower().split(' ')\n",
    "    for word_0 in words:        \n",
    "        word_list = clean_word(word_0)\n",
    "        for word in word_list:        \n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "            clean_line+=' '+word\n",
    "    original_corpus.append(line)\n",
    "    clean_corpus.append(clean_line.strip())\n",
    "email_words=word_freqs.keys()            \n",
    "print(len(email_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4645"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "keyword_list_new=[]\n",
    "keyword_list = set(email_words)\n",
    "for item in keyword_list:\n",
    "    is_re_list = False\n",
    "    for pattern1 in re_pattern_list:\n",
    "        result=re.findall(pattern1, item)\n",
    "        if  len(result) > 0:\n",
    "            is_re_list = True\n",
    "            break\n",
    "    if is_re_list == False:\n",
    "        keyword_list_new.append(item)\n",
    "len(keyword_list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出無母音的關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list_NoVowel={}\n",
    "i=0\n",
    "for word in keyword_list_new:\n",
    "    if not set('aeiou').intersection(word) and len(word.replace('=','')) > 0 and len(word.replace('+','')) > 0 :\n",
    "        if word in keyword_list_NoVowel.keys():\n",
    "            keyword_list_NoVowel[word]+=1\n",
    "        else:\n",
    "            keyword_list_NoVowel[word]=1\n",
    "#print(keyword_list_NoVowel.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list_NoVowel_2.pickle\", 'wb') as f:\n",
    "    pickle.dump(keyword_list_NoVowel, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load List of Microsoft software and Ubuntu Glossaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list.pickle\", 'rb') as f:\n",
    "    keyword_list_TERM = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare corpus with n-gram keywords, n=2~4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_special_term(words, start_index, n_gram):\n",
    "    merge_word=[]\n",
    "    for i in range(n_gram):\n",
    "        merge_word.append(words[start_index+i])\n",
    "    if ' '.join(merge_word) in keyword_list_TERM:\n",
    "        #print('converted_word=', keyword_list_TERM[' '.join(merge_word)]['converted_word'])\n",
    "        return keyword_list_TERM[' '.join(merge_word)]['converted_word']\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def compare_corpus_with_keyword(clean_corpus):\n",
    "    new_clean_corpus=[]\n",
    "    merge_word_list=[] # n-gram keywords\n",
    "    hit_row_index=[] # keep for predict test\n",
    "    for no, line in enumerate(clean_corpus):\n",
    "        words = line.split(' ')\n",
    "        #words = word_tokenize(line) \n",
    "        words_len = len(words)\n",
    "        # n-gram\n",
    "        new_line=''\n",
    "        for i in range(4, 1, -1):\n",
    "            for j in range(words_len-i+1):\n",
    "                merge_word = check_special_term(words, j, i)\n",
    "                if merge_word == '':\n",
    "                    new_line+=' '+words[j]\n",
    "                    if j==words_len-i:\n",
    "                        for k in range(j+1, words_len):\n",
    "                            new_line+=' '+words[k]\n",
    "                    continue\n",
    "                else:\n",
    "                    merge_word_list.append(merge_word)\n",
    "                    hit_row_index.append(no)\n",
    "                    new_line+=' '+merge_word\n",
    "                    j+=i\n",
    "                    continue\n",
    "\n",
    "            # line is too short, keep it as original\n",
    "            if words_len-i<0:\n",
    "                new_line=line    \n",
    "            new_line = new_line.strip()\n",
    "            words = new_line.split(' ')\n",
    "            words_len = len(words)\n",
    "            if i>2:\n",
    "                new_line=''\n",
    "        new_clean_corpus.append(new_line)\n",
    "        #if new_line != line:\n",
    "        #    print('org_line='+line+'\\n')\n",
    "        #    print('new_line='+new_line+'\\n\\n')\n",
    "    return new_clean_corpus, merge_word_list, hit_row_index\n",
    "\n",
    "new_clean_corpus, merge_word_list, hit_row_index = compare_corpus_with_keyword(clean_corpus)\n",
    "hit_row_index=list(set(hit_row_index))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "BOW_vector = vectorizer.fit_transform(new_clean_corpus)\n",
    "X = BOW_vector.toarray()\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34012, 4634)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import guidedlda\n",
    "\n",
    "#X = guidedlda.datasets.load_data(guidedlda.datasets.NYT)\n",
    "#vocab = guidedlda.datasets.load_vocab(guidedlda.datasets.NYT)\n",
    "word2id = dict((v, idx) for idx, v in enumerate(vocab))\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117323\n"
     ]
    }
   ],
   "source": [
    "print(X.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4634"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'abi',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abo',\n",
       " 'abort',\n",
       " 'abr',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'acad']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 34012\n",
      "INFO:guidedlda:vocab_size: 4634\n",
      "INFO:guidedlda:n_words: 117323\n",
      "INFO:guidedlda:n_topics: 30\n",
      "INFO:guidedlda:n_iter: 100\n",
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "INFO:guidedlda:<0> log likelihood: -1321626\n",
      "INFO:guidedlda:<20> log likelihood: -792335\n",
      "INFO:guidedlda:<40> log likelihood: -739597\n",
      "INFO:guidedlda:<60> log likelihood: -717139\n",
      "INFO:guidedlda:<80> log likelihood: -705122\n",
      "INFO:guidedlda:<99> log likelihood: -696469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x1f7146a9d30>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal LDA without seeding\n",
    "model = guidedlda.GuidedLDA(n_topics=30, n_iter=100, random_state=7, refresh=20)\n",
    "model.fit(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顯示每個Topics前八個重要的單字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: security inquiry product agent deploy business service install\n",
      "Topic 1: uninstall tool agent request security wfb password removal\n",
      "Topic 2: agent security uninstall installation issue offline password uninstallation\n",
      "Topic 3: service agent protection install start mac installation unable\n",
      "Topic 4: false positive file detection application detect virus ufe\n",
      "Topic 5: issue performance high usage cpu application wfb quickbook\n",
      "Topic 6: file exclusion program block quarantine application exclude add\n",
      "Topic 7: space disk inquiry server request log folder invalid\n",
      "Topic 8: activate license account code change clp password new\n",
      "Topic 9: service request threat support corporate inquiry master patch\n",
      "Topic 10: file encryption unauthorized infection ransomware detect malware false\n",
      "Topic 11: license seat issue add count information inquiry console\n",
      "Topic 12: scan inquiry schedule time product report configuration notification\n",
      "Topic 13: license inquiry concern threat product renewal status account\n",
      "Topic 14: server new security agent install migrate worry free\n",
      "Topic 15: scan smart update pattern ransomware service infection disconnected\n",
      "Topic 16: exclusion configuration list block device url setting notification\n",
      "Topic 17: agent console offline showing web security license appear\n",
      "Topic 18: agent install update unable security window patch remnant\n",
      "Topic 19: agent install installation error security unable mac offline\n",
      "Topic 20: agent install deploy security wfb free worry client\n",
      "Topic 21: agent security server install offline unable new migrate\n",
      "Topic 22: url block filter website reclassification email http notification\n",
      "Topic 23: console access web unable error upgrade password server\n",
      "Topic 24: install agent unable mac installation issue software error\n",
      "Topic 25: security agent deploy installation business service issue assistance\n",
      "Topic 26: email issue window performance server update spam notification\n",
      "Topic 27: inquiry upgrade product wfb patch version installation issue\n",
      "Topic 28: uninstall log upgrade service error unable wfb display\n",
      "Topic 29: console agent web access upgrade missing wfb showing\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加重特定單字在某些Topics的權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 34012\n",
      "INFO:guidedlda:vocab_size: 4634\n",
      "INFO:guidedlda:n_words: 117323\n",
      "INFO:guidedlda:n_topics: 30\n",
      "INFO:guidedlda:n_iter: 100\n",
      "WARNING:guidedlda:all zero row in document-term matrix found\n",
      "INFO:guidedlda:<0> log likelihood: -1314406\n",
      "INFO:guidedlda:<20> log likelihood: -771597\n",
      "INFO:guidedlda:<40> log likelihood: -725629\n",
      "INFO:guidedlda:<60> log likelihood: -705498\n",
      "INFO:guidedlda:<80> log likelihood: -696754\n",
      "INFO:guidedlda:<99> log likelihood: -691446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<guidedlda.guidedlda.GuidedLDA at 0x1f714691080>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guided LDA with seed topics.\n",
    "seed_topic_list = [['exhange', 'exhange-server', 'server', 'email'],\n",
    "                   ['excel', 'office', 'powerpoint', 'word'],\n",
    "                   ['install', 'antivirus'],\n",
    "                   ['update', 'upgrade ', 'antivirus', 'migrate'],\n",
    "                   ['uninstall', 'antivirus'],\n",
    "                   ['license', 'expire', 'renew', 'activate'],\n",
    "                   ['security', 'agent'],\n",
    "                   ['web', 'url', 'http', 'block'],\n",
    "                   ['console'],\n",
    "                   ['performance', 'slow'],\n",
    "                   ['virus', 'scan', 'malware', 'detect', 'infection'],\n",
    "                  ]\n",
    "\n",
    "model = guidedlda.GuidedLDA(n_topics=30, n_iter=100, random_state=7, refresh=20)\n",
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        if not word in word2id.keys():\n",
    "            word2id[word] = t_id\n",
    "\n",
    "        seed_topics[word2id[word]] = t_id\n",
    "model.fit(X, seed_topics=seed_topics, seed_confidence=0.15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顯示每個Topics前八個重要的單字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: server new migrate agent migration security wfb install client another\n",
      "Topic 1: file false positive quarantine detection restore delete detect ufe unable\n",
      "Topic 2: install agent unable installation error security fail mac patch remnant\n",
      "Topic 3: update scan agent smart pattern service server security disconnected available\n",
      "Topic 4: uninstall tool request agent password wfb security removal needs need\n",
      "Topic 5: device file inquiry exclusion control analysis log folder virus issue\n",
      "Topic 6: license seat activate issue renewal inquiry code account add renew\n",
      "Topic 7: agent security install uninstall unable deploy offline installation reinstall assistance\n",
      "Topic 8: url block filter website application program working reclassification whitelist approve\n",
      "Topic 9: console agent web access showing offline unable page display appear\n",
      "Topic 10: issue performance high usage cpu disk server space slow cause\n",
      "Topic 11: scan schedule infection inquiry time malware smart possible update machine\n",
      "Topic 12: notification error inquiry configuration server log get setting micro email\n",
      "Topic 13: agent security uninstall install wfb deploy unable server worry password\n",
      "Topic 14: inquiry license threat concern detection malware product detect clean action\n",
      "Topic 15: ransomware agent install installation infection mac protection unable device deploy\n",
      "Topic 16: exclusion add list program configuration monitor block behavior application inquiry\n",
      "Topic 17: console access web error unable upgrade server wfb open issue\n",
      "Topic 18: agent security offline install uninstall unable update window upgrade uninstallation\n",
      "Topic 19: update issue window patch agent installation server security install performance\n",
      "Topic 20: business security service free worry advanced product standard installation update\n",
      "Topic 21: installation agent security error issue server fail wfb service micro\n",
      "Topic 22: service support threat request corporate master start stop stopping unavailable\n",
      "Topic 23: window install bsod account system update inquiry pro micro surface\n",
      "Topic 24: deploy agent issue installation mac install unable working block wfb\n",
      "Topic 25: file false encryption unauthorized positive detect detection application ufe tag\n",
      "Topic 26: email block application spam file detect quarantine get malicious attachment\n",
      "Topic 27: inquiry product upgrade wfb version deploy patch update license assistance\n",
      "Topic 28: account password license change clp login reset log unable error\n",
      "Topic 29: console agent upgrade wfb machine web running client computer issue\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "topic_word = model.topic_word_\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 顯示每個Document所屬的Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:guidedlda:all zero row in document-term matrix found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature full installation mac\n",
      "top topic: 15 Document: mac, feature, full, installation, 顯示離線\n",
      " \n",
      "scan smart update\n",
      "top topic: 3 Document: smart, update, scan, hive, hkey\n",
      " \n",
      "installation issue\n",
      "top topic: 21 Document: issue, installation, hook, hlt, hoax\n",
      " \n",
      "ransomware wallet\n",
      "top topic: 15 Document: ransomware, wallet, 顯示離線, hlog, hlt\n",
      " \n",
      "client detection machine possible ransomware wfb\n",
      "top topic: 11 Document: machine, client, wfb, detection, possible\n",
      " \n",
      "add behavior exclusion monitor\n",
      "top topic: 16 Document: add, exclusion, monitor, behavior, home\n",
      " \n",
      "migrate new old server\n",
      "top topic: 0 Document: server, old, migrate, new, hold\n",
      " \n",
      "agent clone\n",
      "top topic: 7 Document: agent, clone, hook, hlt, hoax\n",
      " \n",
      "agent function main micro security software\n",
      "top topic: 7 Document: main, function, micro, agent, security\n",
      " \n",
      "application detect false positive trojan\n",
      "top topic: 25 Document: positive, false, detect, trojan, application\n",
      " \n",
      "active consume disk folder large space update\n",
      "top topic: 10 Document: update, active, disk, large, space\n",
      " \n",
      "administrator check defense disable enter get message notification outbreak web\n",
      "top topic: 12 Document: check, disable, enter, message, notification\n",
      " \n",
      "uninstall\n",
      "top topic: 4 Document: uninstall, 顯示離線, henry, hkey, hlog\n",
      " \n",
      "agent error get install message micro security stop\n",
      "top topic: 21 Document: error, agent, stop, micro, message\n",
      " \n",
      "\n",
      "top topic: 0 Document: 顯示離線, icrc, hlog, hlt, hoax\n",
      " \n",
      "archivo wfb\n",
      "top topic: 22 Document: archivo, wfb, hotchip, hot, hostname\n",
      " \n",
      "reclassification url\n",
      "top topic: 8 Document: url, reclassification, hook, hlog, hlt\n",
      " \n",
      "issue license merge\n",
      "top topic: 6 Document: issue, merge, license, home, hlog\n",
      " \n",
      "false positive rtl\n",
      "top topic: 25 Document: positive, false, rtl, hook, hlt\n",
      " \n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.transform(X)\n",
    "for i in range(19):\n",
    "    doc=[]\n",
    "    vocab_len = len(vocab)\n",
    "    for j in range(vocab_len):\n",
    "        if X[i, j] != 0:\n",
    "            doc.append(vocab[j])\n",
    "    print(' '.join(doc))\n",
    "    \n",
    "    print(\"top topic: {} Document: {}\".format(doc_topic[i].argmax(),\n",
    "          ', '.join(np.array(vocab)[list(reversed(X[i,:].argsort()))[0:5]])))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lighten the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will delete some matrices inside the model.\n",
    "model.purge_extra_matrices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "with open('guidedlda_model.pickle', 'wb') as file_handle:\n",
    "    pickle.dump(model, file_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('guidedlda_model.pickle', 'rb') as file_handle:\n",
    "    model = pickle.load(file_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:guidedlda:all zero row in document-term matrix found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature full installation mac\n",
      "top topic: 15 Document: mac, feature, full, installation, 顯示離線\n",
      " \n",
      "scan smart update\n",
      "top topic: 3 Document: smart, update, scan, hive, hkey\n",
      " \n",
      "installation issue\n",
      "top topic: 21 Document: issue, installation, hook, hlt, hoax\n",
      " \n",
      "ransomware wallet\n",
      "top topic: 15 Document: ransomware, wallet, 顯示離線, hlog, hlt\n",
      " \n",
      "client detection machine possible ransomware wfb\n",
      "top topic: 11 Document: machine, client, wfb, detection, possible\n",
      " \n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.transform(X)\n",
    "for i in range(5):\n",
    "    doc=[]\n",
    "    vocab_len = len(vocab)\n",
    "    for j in range(vocab_len):\n",
    "        if X[i, j] != 0:\n",
    "            doc.append(vocab[j])\n",
    "    print(' '.join(doc))\n",
    "    \n",
    "    print(\"top topic: {} Document: {}\".format(doc_topic[i].argmax(),\n",
    "          ', '.join(np.array(vocab)[list(reversed(X[i,:].argsort()))[0:5]])))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
