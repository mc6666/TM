{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corpus data clean and get keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://test.pypi.org/simple/ krovetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>ACCOUNTID</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CLOSEDDATE</th>\n",
       "      <th>ISESCALATED</th>\n",
       "      <th>CREATEDDATE</th>\n",
       "      <th>TS_PRODUCT_NAME__C</th>\n",
       "      <th>TS_PRODUCT_VERSION__C</th>\n",
       "      <th>TS_EMAIL_TEXTBODY__C</th>\n",
       "      <th>TS_CASE_SUPPORT_REGION__C</th>\n",
       "      <th>FAQID</th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000B00000dG79dQAC</td>\n",
       "      <td>514391</td>\n",
       "      <td>001U000000POQggIAH</td>\n",
       "      <td>Hi, we are a TM reseller and we have a custome...</td>\n",
       "      <td>2017-08-03 13:27:55</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-26 18:33:24</td>\n",
       "      <td>Worry Free Services for Dell</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Hi Kevin,\\n\\nI will now proceed in closing thi...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1102395;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000B00000gxIc8QAE</td>\n",
       "      <td>681829</td>\n",
       "      <td>001U0000016Y6SBIA0</td>\n",
       "      <td>My computer was encrypted while using your pro...</td>\n",
       "      <td>2018-02-22 14:48:55</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-05 16:26:37</td>\n",
       "      <td>Worry Free Services for Dell</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Hi Dennis,\\n\\nI will now proceed in closing th...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1039099;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000B00000ZlwGfQAJ</td>\n",
       "      <td>309921</td>\n",
       "      <td>001U000000fwMAWIA2</td>\n",
       "      <td>AC: WF-3VB2-XLSDL-33VTA-6GZP8-A4ASM-8AJFN</td>\n",
       "      <td>2017-01-10 18:14:24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-08 13:53:53</td>\n",
       "      <td>Worry-Free Bs Services For Dell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on the Trend Micro website and want to kno...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1038246;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000B00000Z9WUNQA3</td>\n",
       "      <td>306770</td>\n",
       "      <td>001U000000gAy3qIAC</td>\n",
       "      <td>[Customer Information]\\nCustomer's Name: craig...</td>\n",
       "      <td>2017-01-02 18:32:05</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-02 18:15:26</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi Craig,\\n\\nThis would be the article for mig...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1037744;1060319;</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5000B00000ZlimFQAR</td>\n",
       "      <td>309036</td>\n",
       "      <td>001U000000gxDh4IAE</td>\n",
       "      <td>This is in reference to an older ticket that I...</td>\n",
       "      <td>2017-02-01 14:02:16</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-05 20:57:53</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Dear Chris,\\n\\nUpon reviewing your Service Req...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1112119;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000B00000ZlpUmQAJ</td>\n",
       "      <td>309629</td>\n",
       "      <td>001U000000TPosUIAT</td>\n",
       "      <td>Name: Levi Swanson\\nSession ID: 495099828\\nSta...</td>\n",
       "      <td>2017-01-07 2:05:28</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-06 18:10:11</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>9</td>\n",
       "      <td>Hi Levi,\\n\\nGood day! \\n\\nThis is Paolo from T...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1039099;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5000B00000Z9ZmtQAF</td>\n",
       "      <td>307096</td>\n",
       "      <td>001U000000PPeRcIAL</td>\n",
       "      <td>[Environment]\\n-Product: \\t\\t\\t\\t[WFBS-A]\\n-OS...</td>\n",
       "      <td>2017-01-03 15:59:25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-03 14:33:30</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi Dana,\\n\\nThis is the article regarding your...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1061328;</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5000B00000ZlkSgQAJ</td>\n",
       "      <td>309114</td>\n",
       "      <td>001U000000fxWvVIAU</td>\n",
       "      <td>[Customer Information]\\nCustomer's Name: lesli...</td>\n",
       "      <td>2017-01-06 0:46:39</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-06 0:39:14</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi Leslie,\\n\\nThis is the article for reconnec...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1037744;</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5000B00000ZmB7zQAF</td>\n",
       "      <td>311588</td>\n",
       "      <td>001U000000fwlJkIAI</td>\n",
       "      <td>When I attempt to install the client on a Wind...</td>\n",
       "      <td>2017-02-07 16:27:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-10 17:20:55</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Hi Ed,\\n\\nFor the meantime, we will proceed to...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1057653;</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000B00000Z9gr3QAB</td>\n",
       "      <td>307476</td>\n",
       "      <td>001U0000010RuBuIAK</td>\n",
       "      <td>Trend Micro Messaging Security Agent Master Se...</td>\n",
       "      <td>2017-01-05 15:14:12</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-04 1:16:57</td>\n",
       "      <td>Worry-Free Business Security Advanced</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Patrick,\\n\\nLast night I updated our Exchange ...</td>\n",
       "      <td>NABU</td>\n",
       "      <td>1096694;1037599;</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID       A           ACCOUNTID  \\\n",
       "0  5000B00000dG79dQAC  514391  001U000000POQggIAH   \n",
       "1  5000B00000gxIc8QAE  681829  001U0000016Y6SBIA0   \n",
       "2  5000B00000ZlwGfQAJ  309921  001U000000fwMAWIA2   \n",
       "3  5000B00000Z9WUNQA3  306770  001U000000gAy3qIAC   \n",
       "4  5000B00000ZlimFQAR  309036  001U000000gxDh4IAE   \n",
       "5  5000B00000ZlpUmQAJ  309629  001U000000TPosUIAT   \n",
       "6  5000B00000Z9ZmtQAF  307096  001U000000PPeRcIAL   \n",
       "7  5000B00000ZlkSgQAJ  309114  001U000000fxWvVIAU   \n",
       "8  5000B00000ZmB7zQAF  311588  001U000000fwlJkIAI   \n",
       "9  5000B00000Z9gr3QAB  307476  001U0000010RuBuIAK   \n",
       "\n",
       "                                         DESCRIPTION           CLOSEDDATE  \\\n",
       "0  Hi, we are a TM reseller and we have a custome...  2017-08-03 13:27:55   \n",
       "1  My computer was encrypted while using your pro...  2018-02-22 14:48:55   \n",
       "2          AC: WF-3VB2-XLSDL-33VTA-6GZP8-A4ASM-8AJFN  2017-01-10 18:14:24   \n",
       "3  [Customer Information]\\nCustomer's Name: craig...  2017-01-02 18:32:05   \n",
       "4  This is in reference to an older ticket that I...  2017-02-01 14:02:16   \n",
       "5  Name: Levi Swanson\\nSession ID: 495099828\\nSta...   2017-01-07 2:05:28   \n",
       "6  [Environment]\\n-Product: \\t\\t\\t\\t[WFBS-A]\\n-OS...  2017-01-03 15:59:25   \n",
       "7  [Customer Information]\\nCustomer's Name: lesli...   2017-01-06 0:46:39   \n",
       "8  When I attempt to install the client on a Wind...  2017-02-07 16:27:06   \n",
       "9  Trend Micro Messaging Security Agent Master Se...  2017-01-05 15:14:12   \n",
       "\n",
       "   ISESCALATED          CREATEDDATE                     TS_PRODUCT_NAME__C  \\\n",
       "0            0  2017-07-26 18:33:24           Worry Free Services for Dell   \n",
       "1            0  2018-01-05 16:26:37           Worry Free Services for Dell   \n",
       "2            0  2017-01-08 13:53:53        Worry-Free Bs Services For Dell   \n",
       "3            0  2017-01-02 18:15:26  Worry-Free Business Security Advanced   \n",
       "4            0  2017-01-05 20:57:53  Worry-Free Business Security Advanced   \n",
       "5            0  2017-01-06 18:10:11  Worry-Free Business Security Advanced   \n",
       "6            0  2017-01-03 14:33:30  Worry-Free Business Security Advanced   \n",
       "7            0   2017-01-06 0:39:14  Worry-Free Business Security Advanced   \n",
       "8            0  2017-01-10 17:20:55  Worry-Free Business Security Advanced   \n",
       "9            0   2017-01-04 1:16:57  Worry-Free Business Security Advanced   \n",
       "\n",
       "  TS_PRODUCT_VERSION__C                               TS_EMAIL_TEXTBODY__C  \\\n",
       "0        Not Applicable  Hi Kevin,\\n\\nI will now proceed in closing thi...   \n",
       "1                   5.3  Hi Dennis,\\n\\nI will now proceed in closing th...   \n",
       "2                   NaN  I'm on the Trend Micro website and want to kno...   \n",
       "3                   NaN  Hi Craig,\\n\\nThis would be the article for mig...   \n",
       "4                   9.0  Dear Chris,\\n\\nUpon reviewing your Service Req...   \n",
       "5                     9  Hi Levi,\\n\\nGood day! \\n\\nThis is Paolo from T...   \n",
       "6                   NaN  Hi Dana,\\n\\nThis is the article regarding your...   \n",
       "7                   NaN  Hi Leslie,\\n\\nThis is the article for reconnec...   \n",
       "8                   9.0  Hi Ed,\\n\\nFor the meantime, we will proceed to...   \n",
       "9                   9.0  Patrick,\\n\\nLast night I updated our Exchange ...   \n",
       "\n",
       "  TS_CASE_SUPPORT_REGION__C             FAQID Column1  \n",
       "0                      NABU          1102395;       Y  \n",
       "1                      NABU          1039099;       Y  \n",
       "2                      NABU          1038246;       Y  \n",
       "3                      NABU  1037744;1060319;       N  \n",
       "4                      NABU          1112119;       Y  \n",
       "5                      NABU          1039099;       Y  \n",
       "6                      NABU          1061328;       N  \n",
       "7                      NABU          1037744;       Y  \n",
       "8                      NABU          1057653;       N  \n",
       "9                      NABU  1096694;1037599;       N  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./NABU FAQ for Worry Free Product 20190401.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import krovetz\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words=stopwords.words('english')\n",
    "break_words=list('\\n\\t')\n",
    "prefix_char_remove=list('.*,-')\n",
    "\n",
    "stemmer = krovetz.PyKrovetzStemmer()\n",
    "#stemmer = SnowballStemmer(\"english\")\n",
    "#stemmer.stem('working')\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "word_freqs = dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字詞清理函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "```\n",
    "import krovetz\n",
    "ks = krovetz.PyKrovetzStemmer()\n",
    "ks.stem('Microsoft Edge'.lower()) # 使用 NLTK stemming 會傳回字根(會漏字母 e)，而非原形\n",
    "ks.stem('working'.lower()) # 無法去除 ing\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used\n",
    "def stem_phrase(word_0):\n",
    "    word_list=[]\n",
    "    for word in word_0.split(' '):\n",
    "        word_list.append(stemmer.stem(word))\n",
    "        print(word, stemmer.stem(word))\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "# clean words\n",
    "def clean_word(word_0):\n",
    "    word_list=[]\n",
    "    for word in word_0.split('/'):\n",
    "\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "\n",
    "        remote_path=word.split('\\\\')\n",
    "        if len(remote_path) > 0 and len(remote_path[-1])>0:\n",
    "            word=remote_path[-1]\n",
    "        elif len(remote_path) > 1 and len(remote_path[-2])>0:\n",
    "            word=remote_path[-2]\n",
    "        elif len(remote_path) > 2 and len(remote_path[-3])>0:\n",
    "            word=remote_path[-3]\n",
    "\n",
    "        if word[0] == '\"' and word[-1] == '\"':\n",
    "            word=word[1:-1]\n",
    "        if word[0] == \"'\" and word[-1] == \"'\":\n",
    "            word=word[1:-1]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "\n",
    "        # repeat 3 times to remove continous chars\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "        if len(word) <= 0 :\n",
    "            continue\n",
    "        if word[0] in prefix_char_remove:\n",
    "            word=word[1:]\n",
    "\n",
    "        # lemmatize\n",
    "        word=word.strip().lower()\n",
    "        word=stemmer.stem(word)\n",
    "        if word=='':\n",
    "            continue      \n",
    "            \n",
    "        # remove .exe and .com\n",
    "        if word.endswith('.exe') or word.endswith('.com'):\n",
    "            word=word[:-4]\n",
    "            \n",
    "        # remove the words with one or two characters only\n",
    "        if len(word) <= 2 :\n",
    "            continue\n",
    "        if not (word in stop_words):\n",
    "            word_list.append(word)\n",
    "               \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test clean_word()\n",
    "```\n",
    "line = 'server\\\\pccsrv\\\\wss\\\\spsc\\\\bin aaa'\n",
    "words = word_tokenize(line) #line.lower().split(' ')\n",
    "for word_0 in words:        \n",
    "    clean_word(word_0)\n",
    "email_words=word_freqs.keys()            \n",
    "print(email_words)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6976\n"
     ]
    }
   ],
   "source": [
    "# 清理後的 email DESCRIPTION\n",
    "clean_corpus=[]\n",
    "original_corpus=[]\n",
    "for index, line in df.iterrows():\n",
    "    clean_line=\"\"\n",
    "    line = line['DESCRIPTION']\n",
    "    for break_word in break_words:\n",
    "        #print('-',len(break_word), break_word, '-')\n",
    "        line = line.replace(break_word, ' ')\n",
    "    words = word_tokenize(line) #line.lower().split(' ')\n",
    "    for word_0 in words:        \n",
    "        word_list = clean_word(word_0)\n",
    "        for word in word_list:        \n",
    "            if word in word_freqs:\n",
    "                word_freqs[word] += 1\n",
    "            else:\n",
    "                word_freqs[word] = 1\n",
    "            clean_line+=' '+word\n",
    "    original_corpus.append(line)\n",
    "    clean_corpus.append(clean_line.strip())\n",
    "email_words=word_freqs.keys()            \n",
    "print(len(email_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以 regular expression 去除 email、數字、URL、Phone No、序號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_pattern_list=[]\n",
    "re_pattern_list.append('[a-zA-Z0-9_]+\\.(com|org|net)[a-zA-Z0-9_\\.]*$') #email\n",
    "re_pattern_list.append('[0-9_]+') # all digits\n",
    "re_pattern_list.append(\"\\/\\/[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&'\\(\\)\\*\\+,;=.]+$\") # url\n",
    "re_pattern_list.append('[0-9\\-]+') # phone no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4804"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "keyword_list_new=[]\n",
    "keyword_list = set(email_words)\n",
    "for item in keyword_list:\n",
    "    is_re_list = False\n",
    "    for pattern1 in re_pattern_list:\n",
    "        result=re.findall(pattern1, item)\n",
    "        if  len(result) > 0:\n",
    "            is_re_list = True\n",
    "            break\n",
    "    if is_re_list == False:\n",
    "        keyword_list_new.append(item)\n",
    "len(keyword_list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出無母音的關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list_NoVowel={}\n",
    "i=0\n",
    "for word in keyword_list_new:\n",
    "    if not set('aeiou').intersection(word) and len(word.replace('=','')) > 0 and len(word.replace('+','')) > 0 :\n",
    "        if word in keyword_list_NoVowel.keys():\n",
    "            keyword_list_NoVowel[word]+=1\n",
    "        else:\n",
    "            keyword_list_NoVowel[word]=1\n",
    "#print(keyword_list_NoVowel.keys())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save 無母音的關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list_NoVowel.pickle\", 'wb') as f:\n",
    "    pickle.dump(keyword_list_NoVowel, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get List of Microsoft software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "# keyword_list_TERM： {key:{converted_word, count}}\n",
    "keyword_list_TERM={}\n",
    "html_page = urlopen(\"https://en.wikipedia.org/wiki/List_of_Microsoft_software\")\n",
    "soup = BeautifulSoup(html_page)\n",
    "div = soup.find('div', attrs={'id': 'mw-content-text'})\n",
    "footer = str(div.contents).rfind(\"Misc.\")\n",
    "\n",
    "for link in div.findAll('a', attrs={'href': re.compile(\"/wiki/\")}): #\"^https://\")}):\n",
    "    link_text = link.text.replace('+','').lower().strip()\n",
    "    # lemmatize\n",
    "    link_text=stemmer.stem(link_text)\n",
    "    #if link_text=='Microsoft Edge'.lower():\n",
    "    #    print(stemmer.stem(link_text))\n",
    "    if link_text in keyword_list_TERM.keys():\n",
    "        keyword_list_TERM[link_text]['count']+=1\n",
    "    else:\n",
    "        keyword_list_TERM[link_text]={'converted_word':link_text.replace(\" \", \"_\")}\n",
    "        keyword_list_TERM[link_text]['count']=1\n",
    "\n",
    "    link_text = link.text.replace('+','').lower().replace('microsoft', 'ms').strip()\n",
    "    # lemmatize\n",
    "    link_text=stemmer.stem(link_text)\n",
    "    if link_text in keyword_list_TERM.keys():\n",
    "        keyword_list_TERM[link_text]['count']+=1\n",
    "    else:\n",
    "        keyword_list_TERM[link_text]={'converted_word':link_text.replace(\" \", \"_\")}\n",
    "        keyword_list_TERM[link_text]['count']=1\n",
    "\n",
    "    link_text = link.text.replace('+','').lower().replace('microsoft', '').strip()\n",
    "    # lemmatize\n",
    "    link_text=stemmer.stem(link_text)\n",
    "    if link_text in keyword_list_TERM.keys():\n",
    "        keyword_list_TERM[link_text]['count']+=1\n",
    "    else:\n",
    "        keyword_list_TERM[link_text]={'converted_word':link_text.replace(\" \", \"_\")}\n",
    "        keyword_list_TERM[link_text]['count']=1\n",
    "        \n",
    "    #print (link_text)\n",
    "    if link_text == 'Windows To Go'.lower(): \n",
    "        break\n",
    "\n",
    "link_text= 'window'       \n",
    "if link_text in keyword_list_TERM.keys():\n",
    "    keyword_list_TERM[link_text]['count']+=1\n",
    "else:\n",
    "    keyword_list_TERM[link_text]={'converted_word':link_text}\n",
    "    keyword_list_TERM[link_text]['count']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list=list(keyword_list_TERM.keys())\n",
    "for key1 in key_list:\n",
    "    if key1.startswith('list of '):\n",
    "        del keyword_list_TERM[key1]\n",
    "#keyword_list_TERM.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Ubuntu Glossaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "\n",
    "html_page = urlopen(\"https://help.ubuntu.com/community/Glossary\")\n",
    "soup = BeautifulSoup(html_page)\n",
    "for link in soup.findAll('p', attrs={'class': re.compile(\"^line\")}): #\"^https://\")}):\n",
    "    strong_tag = link.find('strong')\n",
    "    if not strong_tag == None:\n",
    "        strong_tag_text = strong_tag.text.lower().strip()\n",
    "        strong_tag_text=stemmer.stem(strong_tag_text)\n",
    "        if strong_tag_text == 'Contributors:'.lower():\n",
    "            break\n",
    "        if strong_tag_text.find('(or') >= 0 and strong_tag_text.endswith(')'):\n",
    "            #print('two_glossary={}'.format(strong_tag_text))\n",
    "            two_glossary = strong_tag_text.split('(or')\n",
    "            for item in two_glossary:\n",
    "                item=item.strip().replace(\")\", '')\n",
    "                item=stemmer.stem(item)\n",
    "                if item in keyword_list_TERM.keys():\n",
    "                    keyword_list_TERM[item]['count']+=1\n",
    "                else:\n",
    "                    keyword_list_TERM[item]={'converted_word':item.replace(\" \", \"_\")}\n",
    "                    keyword_list_TERM[item]['count']=1\n",
    "        else:    \n",
    "            if strong_tag_text.find('(also') >= 0 :\n",
    "                strong_tag_text=strong_tag_text[:strong_tag_text.find('(also')]\n",
    "            strong_tag_text=strong_tag_text\n",
    "            if strong_tag_text.find('ubuntu') >= 0 :\n",
    "                strong_tag_text='ubuntu'\n",
    "            if strong_tag_text in keyword_list_TERM.keys():\n",
    "                keyword_list_TERM[strong_tag_text]['count']+=1\n",
    "            else:\n",
    "                keyword_list_TERM[strong_tag_text]={'converted_word':strong_tag_text.replace(\" \", \"_\")}\n",
    "                keyword_list_TERM[strong_tag_text]['count']=1\n",
    "        #print (strong_tag_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list.pickle\", 'wb') as f:\n",
    "    pickle.dump(keyword_list_TERM, f)\n",
    "#keyword_list_TERM.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save clean and original corpus(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_corpus.txt\", 'w', encoding='utf8') as f:\n",
    "    for line in clean_corpus:\n",
    "        f.write(line.replace('\\n', ' ')+'\\n')\n",
    "with open(\"original_corpus.txt\", 'w', encoding='utf8') as f:\n",
    "    for line in original_corpus:\n",
    "        f.write(line.replace('\\n', ' ')+'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
