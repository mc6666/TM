{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text similarity with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# MS/LINUX glossary 的權重加分\n",
    "keyword_weight_increase = 1\n",
    "# 無母音的單字權重加分\n",
    "keyword_weight_increase_NoVowel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clean_corpus.txt\", 'r', encoding='utf8') as f:\n",
    "    clean_corpus=f.readlines()\n",
    "    for i in range(len(clean_corpus)):\n",
    "        clean_corpus[i]=clean_corpus[i].replace('\\n', '')\n",
    "\n",
    "with open(\"original_corpus.txt\", 'r', encoding='utf8') as f:\n",
    "    original_corpus=f.readlines()\n",
    "    for i in range(len(original_corpus)):\n",
    "        original_corpus[i]=original_corpus[i].replace('\\n', ' ')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list_NoVowel.pickle\", 'rb') as f:\n",
    "    keyword_list_NoVowel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"keyword_list.pickle\", 'rb') as f:\n",
    "    keyword_list_TERM = pickle.load(f)\n",
    "#keyword_list_TERM.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare corpus with n-gram keywords, n=2~4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_special_term(words, start_index, n_gram):\n",
    "    merge_word=[]\n",
    "    for i in range(n_gram):\n",
    "        merge_word.append(words[start_index+i])\n",
    "    if ' '.join(merge_word) in keyword_list_TERM:\n",
    "        #print('converted_word=', keyword_list_TERM[' '.join(merge_word)]['converted_word'])\n",
    "        return keyword_list_TERM[' '.join(merge_word)]['converted_word']\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def compare_corpus_with_keyword(clean_corpus):\n",
    "    new_clean_corpus=[]\n",
    "    merge_word_list=[] # n-gram keywords\n",
    "    hit_row_index=[] # keep for predict test\n",
    "    for no, line in enumerate(clean_corpus):\n",
    "        words = line.split(' ')\n",
    "        #words = word_tokenize(line) \n",
    "        words_len = len(words)\n",
    "        # n-gram\n",
    "        new_line=''\n",
    "        for i in range(4, 1, -1):\n",
    "            for j in range(words_len-i+1):\n",
    "                merge_word = check_special_term(words, j, i)\n",
    "                if merge_word == '':\n",
    "                    new_line+=' '+words[j]\n",
    "                    if j==words_len-i:\n",
    "                        for k in range(j+1, words_len):\n",
    "                            new_line+=' '+words[k]\n",
    "                    continue\n",
    "                else:\n",
    "                    merge_word_list.append(merge_word)\n",
    "                    hit_row_index.append(no)\n",
    "                    new_line+=' '+merge_word\n",
    "                    j+=i\n",
    "                    continue\n",
    "\n",
    "            # line is too short, keep it as original\n",
    "            if words_len-i<0:\n",
    "                new_line=line    \n",
    "            new_line = new_line.strip()\n",
    "            words = new_line.split(' ')\n",
    "            words_len = len(words)\n",
    "            if i>2:\n",
    "                new_line=''\n",
    "        new_clean_corpus.append(new_line)\n",
    "        #if new_line != line:\n",
    "        #    print('org_line='+line+'\\n')\n",
    "        #    print('new_line='+new_line+'\\n\\n')\n",
    "    return new_clean_corpus, merge_word_list, hit_row_index\n",
    "\n",
    "new_clean_corpus, merge_word_list, hit_row_index = compare_corpus_with_keyword(clean_corpus)\n",
    "hit_row_index=list(set(hit_row_index))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1719, 8709)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(new_clean_corpus)\n",
    "print (tfidf.shape)\n",
    "\n",
    "words = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if keyword exists\n",
    "'visual_c' in vectorizer.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_word_list=list(set(merge_word_list))\n",
    "#merge_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list_TERM_converted=[]\n",
    "for item in keyword_list_TERM.keys():\n",
    "    keyword_list_TERM_converted.append(keyword_list_TERM[item]['converted_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change weight of keywords for training data manually\n",
    "def adjust_weight_based_on_keyword(tfidf_1):\n",
    "    # adjust weight based on terminology\n",
    "    for key_term in keyword_list_TERM_converted:\n",
    "        if not key_term in vectorizer.vocabulary_.keys():\n",
    "            continue\n",
    "        key_term_code = vectorizer.vocabulary_[key_term]\n",
    "        #if key_term == 'exchange_server':\n",
    "        #    print(key_term_code)\n",
    "        for row in range(tfidf_1.toarray().shape[0]):\n",
    "            if tfidf_1[row, key_term_code] > 1e-5:\n",
    "                tfidf_1[row,key_term_code]+=keyword_weight_increase\n",
    "                \n",
    "    # adjust weight based on products/services acronym\n",
    "    for key_term in keyword_list_NoVowel.keys():\n",
    "        if not key_term in vectorizer.vocabulary_.keys():\n",
    "            continue\n",
    "        key_term_code = vectorizer.vocabulary_[key_term]\n",
    "        #if key_term == 'exchange_server':\n",
    "        #    print(key_term_code)\n",
    "        for row in range(tfidf_1.toarray().shape[0]):\n",
    "            if tfidf_1[row, key_term_code] > 1e-5:\n",
    "                tfidf_1[row,key_term_code]+=keyword_weight_increase_NoVowel\n",
    "                \n",
    "adjust_weight_based_on_keyword(tfidf)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get adjusted weights of 'exchange_server'\n",
    "```\n",
    "# adjusted weights of 'exchange_server'\n",
    "for row in range(tfidf.toarray().shape[0]):\n",
    "    if tfidf[row, 3745] > 1e-5:\n",
    "        print(tfidf[row,3745])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "works 1.2646511321858687\n",
      "exchange_server 1.2284476755999365\n",
      "wfb 1.1302115289712866\n",
      "security 1.1139505071005387\n",
      "agent 1.111182488361652\n",
      "server 1.0993284265809409\n",
      "smex 0.6230860887022853\n",
      "2010 0.29013768958395175\n",
      "master 0.2532055301506258\n",
      "hour 0.24618505246920577\n",
      "exchange 0.23824448377043922\n"
     ]
    }
   ],
   "source": [
    "# 任選一句預測\n",
    "document2 = [new_clean_corpus[hit_row_index[0]]]\n",
    "\n",
    "new_data = vectorizer.transform(document2)\n",
    "adjust_weight_based_on_keyword(new_data)  \n",
    "\n",
    "#print(new_data.toarray())\n",
    "#print ('-'*20)\n",
    "\n",
    "# print top 10 keywords\n",
    "top10_index_list=np.argsort(new_data.toarray()[0])[::-1][:11]\n",
    "for j in range(len(top10_index_list)):\n",
    "    if new_data[0,top10_index_list[j]]> 1e-5:\n",
    "        print (words[top10_index_list[j]], new_data[0,top10_index_list[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WFBS 10 exchange Messaging Security Agent not working SMEX   Exchange server 2010 SP3 when restart smex master.exe  it works again for 24 hours '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_corpus[hit_row_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0033793  0.         0.         ... 0.         0.28296256 0.        ]\n",
      "[ 384 1607  150  343  448  290  678   57  391 1324  332]\n",
      "new data 原文:[WFBS 10 exchange Messaging Security Agent not working SMEX   Exchange server 2010 SP3 when restart smex master.exe  it works again for 24 hours ]\n",
      "new data 處理後: ['wfb exchange message security agent working smex exchange_server server 2010 sp3 restart smex master works hour']\n",
      "0:WFBS 10 exchange Messaging Security Agent not working SMEX   Exchange server 2010 SP3 when restart smex master.exe  it works again for 24 hours \n",
      "\n",
      "1:Multiple users get this message when they receive email from @listserv.cuis.edu.  Administrators of the listserv report no issues. What would be triggering the detection? Is there a way to whitelist in WFBS Standard?  (We do not use exchange server.)  Message received: \"Subject: Trend Micro OfficeScan detected and took action on a malicious email  Trend Micro Worry-Free Business Security Agent has detected an email that may contain malicious contents and attached it to this new mail as a text file. If you need to read the original mail message, we recommend you open it as a text file. To prevent infection, do not save the original mail as a mail file.\"  Example email attached.  Thank you. Peter \n",
      "\n",
      "2:The assembly path of the transport agent for the Exchange server is pointing to the wrong drive after upgrading to a newer version of the MSA.  The MSA was installed on D, is now installed on C, however the AssemblyPath path of the transport agent still points to d, causing the exchange transport service to crash.  temporary solution was to copy the required files to d, but that is obviously not a long term solution.  the installation of the msa was properly executed to c: via the webinterface by adding a new exchange server and works otherwise \n",
      "\n",
      "3:Customer asking about moving Security Agents to new server -old server is WFBS 9.5 and new server is WFBS 10  -new server is not installed yet \n",
      "\n",
      "4:I had to move the Worry-Free Business Security (WFBS) Advanced console to a new server. I did that.  Once I did, I removed the Messaging Security Agent (MSA) from the Exchange server.   I'm now trying to install the Messaging Security Agent (MSA) from the Worry-Free Business Security (WFBS) Advanced console on the Exchange server. Every time I try it, I get an error that says \"The Installer detected a corrupted Messaging Security Agent on the Exchange Server. Manually remove the corrupted Agent and retry. Refer to the Knowledge Base for instructions.\"  I have tried this but it does not work: https://success.trendmicro.com/solution/1037599-installing-the-messaging-security-agent-msa-from-the-worry-free-business-security-wfbs-advanced  I have tried multiple users: still get the same error. I have tried multiple reboots: still get the same error. \n",
      "\n",
      "5:We are running WFBS Advanced and were migrating servers when our old server crashed.  We can not get it back.  The new version of 9.5 was installed on the new server and only the Exchange Server had been migrated.  When I go to remove the old client agents from the computers in order to install from the new server, the software will not install saying the wrong password has been used.  I can't get into the old server to change it to something usable.  Please advise on what I should do. \n",
      "\n",
      "6:What is the latest officially supported/compatible mac OS that our Trend WFBS Agent works with \n",
      "\n",
      "7:-Issue on installing the MSA on the security server -customer said that they have added an exchange server but is having an issue in adding it on the web console MSA can't be seen or added on the Web console of WFBS  [Customer Information] SR:  00478635 Contact Name:  Brian Warner Phone: 2144353375 E-mail: bwarner@servicead-in.com Company: BKG SERVICE \n",
      "\n",
      "8:Although everything has been updated, we continually get these notifications:  Trend Micro Worry-Free Business Security Notification * Update - At least one outdated Messaging Security Agent after one hour of pattern release. * Report time: 10/9/2018 7:01:23 * Affected Exchange servers: 1 * Suggestion: Ensure that scheduled updates for Messaging Security Agents is enabled on the Security Server and that the Messaging Security Agents can connect to the Internet. \n",
      "\n",
      "9:I am having an issue where my security server is not upgrading.  I thought that I had upgraded to 9 SP3 for WFBS but when I look at the server, it looks like it is not upgraded.  I downloaded WFBS 9.5 this weekend - installed it on the security server but now it appears to still be on 9.0.1384 - I need assistance. \n",
      "\n",
      "10:- Install security server to a new machine - Transfer all the agents to the new server \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 顯示與其他句的相似度\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similar_prob=cosine_similarity(new_data, tfidf.toarray())\n",
    "print (similar_prob[0])\n",
    "\n",
    "similar_corpus_index = np.argsort(similar_prob[0])[::-1][:11]\n",
    "print(similar_corpus_index)\n",
    "print(\"new data 原文:[{}]\".format(original_corpus[hit_row_index[0]]))\n",
    "print(\"new data 處理後:\", document2)\n",
    "for i in range(len(similar_corpus_index)):\n",
    "    #print('{}:{}\\n'.format(i, new_clean_corpus[similar_corpus_index[i]]))\n",
    "    print('{}:{}\\n'.format(i, original_corpus[similar_corpus_index[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
